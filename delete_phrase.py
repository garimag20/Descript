# -*- coding: utf-8 -*-
"""delete_phrase_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XIt21bgi3gHEghUh4gDnp9xwtC7N0hq7
"""

!pip install gradio
!pip install google.cloud.speech
!pip install wavio

import os
import google.cloud.speech as g
import gradio as gr
import wave
from os.path import exists, join, basename, splitext
import sys
import librosa
import wavio
import regex as re
import pandas as pd
import ipywidgets as widgets
import numpy as np
from pydub import AudioSegment
from scipy.io import wavfile
from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip

from google.colab import drive
drive._mount('/content/drive')

os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'/content/drive/MyDrive/Colab Notebooks/credentials.json'

def generate_transcripts(audio):

    client = g.SpeechClient()
    with open(audio.name, 'rb') as f1:
        byte_data_wav = f1.read()
    f1 = wave.open(audio.name, "r")
    
    num_channels_file1 = int(f1.getnchannels())
    
    audio_wav = g.RecognitionAudio(content = byte_data_wav)
#     return "abc"
    config = g.RecognitionConfig(
    enable_automatic_punctuation = True,
    language_code = 'en-US', 
    audio_channel_count= num_channels_file1,
    enable_separate_recognition_per_channel=False,
    enable_word_time_offsets=True,
    )
    operation = client.long_running_recognize(config = config, audio = audio_wav)
    result = operation.result(timeout=90)

    result = operation.result(timeout=90)
    # return "abc"
      
    with open("transcript.txt",'w') as f:
        pass
    s = ""
    with open("transcript.txt", 'a+') as f:
        
        for result in result.results:
            alternative = result.alternatives[0]
            para = alternative.transcript
            print(para, file = f)
            s += para

    result = operation.result(timeout=90)
    with open("timeoffset.csv",'w') as f:
        pass
    with open("timeoffset.csv", 'a+') as f:
            for result in result.results:
                alternative = result.alternatives[0]
                for word_info in alternative.words:
                    word = word_info.word
                    start_time = word_info.start_time
                    end_time = word_info.end_time
                    x = f"Word: {word}, start_time: {start_time.total_seconds()}, end_time: {end_time.total_seconds()}"
                    y = f"{word}, {start_time.total_seconds()}, {end_time.total_seconds()}"
                    print(y, end='\n', file=f)

    # return s

def create_dataframe(audio):
  generate_transcripts(audio)
  df = pd.read_csv(r'/content/timeoffset.csv', header = None, error_bad_lines=False)
  df.rename(columns = {0 : 'Word', 1 : 'start_offset', 2 : 'end_offset'}, inplace = True)
  return df

def delete_phrase(audio, phrase):
 
  df = create_dataframe(audio)
  main_string=open('/content/transcript.txt').read()
  end = df['end_offset'][df.shape[0]-1]
  # print(df[96]['end_offset'])
  # return df.tail()
  list1=[(idx.start(), idx.end()) for idx in re.finditer(phrase, main_string)]
  start_time=df['start_offset'][len(main_string[:list1[0][0]].split())]
  end_time=df['end_offset'][len(main_string[:list1[0][0]].split())+len(phrase.split())-1]
  clip_1 = ffmpeg_extract_subclip(audio.name, 0, start_time, targetname = r"clip_1.wav")
  clip_2 = ffmpeg_extract_subclip(audio.name, end_time, end, targetname = r"clip_2.wav")
  sound1 = AudioSegment.from_wav(r"clip_1.wav")
  sound1 = sound1.fade_out(5)
  sound2 = AudioSegment.from_wav(r"clip_2.wav")
  sound2=sound2.fade_out(5)

  final = sound1+sound2
  final.export(r"final.wav", format="wav")
  sr, audio = wavfile.read('final.wav')
  return sr,audio

iface = gr.Interface(fn=delete_phrase, inputs=["file","text"], outputs="audio", examples=[["/content/drive/MyDrive/test.wav","else don't even"]], title='Delete phrases', description="To delete a phrase in your audio file, upload your audio file in wav format and enter the phrase you want to remove.").launch(share=True)

