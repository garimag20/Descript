# -*- coding: utf-8 -*-
"""Copy of Insertion.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17QlGd1wEgQW7al9isql_xC0V3_G5_lqE
"""

!pip install gradio
#!pip install google.cloud.speech
!pip install wavio

import os
#import google.cloud.speech as g
import gradio as gr
import wave
from os.path import exists, join, basename, splitext
import sys
import librosa
import wavio
import regex as re
import pandas as pd
import ipywidgets as widgets
import numpy as np
from pydub import AudioSegment
from scipy.io import wavfile
from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip

from os.path import exists, join, basename, splitext

git_repo_url = 'https://github.com/CorentinJ/Real-Time-Voice-Cloning.git'
project_name = splitext(basename(git_repo_url))[0]
if not exists(project_name):
  # clone and install
  !git clone -q --recursive {git_repo_url}
  # install dependencies
  !cd {project_name} && pip install -q -r requirements.txt
  !pip install -q gdown
  !apt-get install -qq libportaudio2
  !pip install -q https://github.com/tugstugi/dl-colab-notebooks/archive/colab_utils.zip

  # download pretrained model
  !cd {project_name} && wget https://github.com/blue-fish/Real-Time-Voice-Cloning/releases/download/v1.0/pretrained.zip && unzip -o pretrained.zip

import sys
sys.path.append(project_name)

from IPython.display import display, Audio, clear_output
from IPython.utils import io
import ipywidgets as widgets
import numpy as np
from dl_colab_notebooks.audio import record_audio, upload_audio
from synthesizer.inference import Synthesizer
from encoder import inference as encoder
from vocoder import inference as vocoder
from pathlib import Path

encoder.load_model(project_name / Path("encoder/saved_models/pretrained.pt"))
synthesizer = Synthesizer(project_name / Path("synthesizer/saved_models/pretrained/pretrained.pt"))
vocoder.load_model(project_name / Path("vocoder/saved_models/pretrained/pretrained.pt"))

def insertion(audio, phrase, second):
    in_fpath = Path(audio.name)
    reprocessed_wav = encoder.preprocess_wav(in_fpath)
    original_wav, sampling_rate = librosa.load(in_fpath)
    preprocessed_wav = encoder.preprocess_wav(original_wav, sampling_rate)
    embed = encoder.embed_utterance(preprocessed_wav)
    with io.capture_output() as captured:
      specs = synthesizer.synthesize_spectrograms([phrase], [embed])
    generated_wav = vocoder.infer_waveform(specs[0])
    generated_wav = np.pad(generated_wav, (0, synthesizer.sample_rate), mode="constant")
    
    #display(Audio(generated_wav, rate=synthesizer.sample_rate))
    wavio.write("cloned.wav", generated_wav, synthesizer.sample_rate, sampwidth=3)
    start_time=float(second)
    clips_1 = ffmpeg_extract_subclip(audio.name, 0, start_time, targetname = r"clips_1.wav")
    end=librosa.get_duration(filename=audio.name)
    clips_2 = ffmpeg_extract_subclip(audio.name, start_time, end, targetname = r"clips_2.wav")
    

    sounds1 = AudioSegment.from_wav(r"/content/clips_1.wav")
    sounds1 = sounds1.fade_out(5)
    sounds3 = AudioSegment.from_wav(r"/content/clips_2.wav")
    sounds3 = sounds3.fade_out(5)
    sounds2 = AudioSegment.from_wav(r"/content/cloned.wav")
    sounds2 = sounds2.fade_out(5)
    finals = sounds1+sounds2+sounds3
    finals.export(r"finals.wav", format="wav")
    sr, audio = wavfile.read('finals.wav')
    return sr,audio

insertion("/content/drive/MyDrive/Colab Notebooks/test.wav", "towars", 5)

from google.colab import drive
drive._mount('/content/drive')

iface = gr.Interface(fn=insertion, inputs=["file","text","number"], outputs="audio",examples=[["/content/drive/MyDrive/test.wav","because just don't start",3.9]], title='Insert phrases', description="To insert a phrase in your audio file, upload your audio file in wav format, in the text input enter the phrase to be inserted and in the number input enter the second at which you want the inserted phrase in the audio").launch(share=True)

